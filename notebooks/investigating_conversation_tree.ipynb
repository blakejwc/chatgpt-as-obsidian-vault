{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Function to convert a timestamp to the required format\n",
    "def timestamp_to_str(timestamp):\n",
    "    if timestamp is None:\n",
    "        return 'None'\n",
    "    return datetime.utcfromtimestamp(timestamp).strftime('%y-%m-%d %H:%M')\n",
    "\n",
    "# Load the data\n",
    "with open('../data/conversations.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of small conversations:  173\n",
      "Total conversations:  874\n",
      "--------------------------------------------------\n",
      "Virtual Conferences Solution.: {'0e7a81e7-608d-4120-8776-21f724e13733': {'id': '0e7a81e7-608d-4120-8776-21f724e13733', 'message': {'id': '0e7a81e7-608d-4120-8776-21f724e13733', 'author': {'role': 'system', 'name': None, 'metadata': {}}, 'create_time': 1681977336.611987, 'update_time': None, 'content': {'content_type': 'text', 'parts': ['']}, 'status': 'finished_successfully', 'end_turn': True, 'weight': 1.0, 'metadata': {}, 'recipient': 'all'}, 'parent': 'fb062b48-1505-4354-8362-9b8b338be06d', 'children': ['0ac6d621-f070-4451-826d-bb0a39ee3717']}, 'fb062b48-1505-4354-8362-9b8b338be06d': {'id': 'fb062b48-1505-4354-8362-9b8b338be06d', 'message': None, 'parent': None, 'children': ['0e7a81e7-608d-4120-8776-21f724e13733']}, '0ac6d621-f070-4451-826d-bb0a39ee3717': {'id': '0ac6d621-f070-4451-826d-bb0a39ee3717', 'message': {'id': '0ac6d621-f070-4451-826d-bb0a39ee3717', 'author': {'role': 'user', 'name': None, 'metadata': {}}, 'create_time': 1681977336.614453, 'update_time': None, 'content': {'content_type': 'text', 'parts': ['Context clues:\\n- Paris\\n- biotech\\n- conference\\n- networking\\n- meals\\n- attendees\\n- impact\\n\\nUsing the context clues, give me the unabbreviated version of the following:\\n\\nCnfs r pivtl prt of scntfc entrprs, bt lrg in-prsn mtngs hv svrl dsdvntgs. As pndmc xprnc hs shwn, onln mtngs r viable altrntv. Acclrting effrts to imprv cnfs in vrtl frmts cn ld to a more eqtbl and sustainable cnf cltr.\\n\\nScntfc cnfs r imprtnt avnus fr rshrs to shr and dscss rsrch findings, to exchng ideas and insights, and to ntwrk for collab and career dvlpmnt. Orgnzing incsve and useful scntfc mtngs is a signfct rspnsblty shrd by rshrs, scntfc societies, and other orgs wrldwd. Pr to 2020, most cnfs wr held in-prsn and prvd limited attendance opps fr many rshrs frm diverse socioeconomic bckgrnds, prticulrly early career rshrs (ECRs), rshrs from lw- and mddl-incme ctries, and junior principal investigators (PIs)1. Some cnfs in select disciplines have implmntd valuable changes for the community, bcmng more rcptive to atnds with families. Due to the COVID-19 pandemic, a major shift has occurred twrds vrtl cnf formats, triggering discussions in the scntfc community on the current and future formats and orgnztion of cnfs. Here we provide rcmndations for improving scntfc mtngs twrds more efficient, sustainable, and equitable gatherings.\\nThe many dsdvntgs of in-prsn cnfs\\n\\nWe examined 270 national and international academic cnfs held in person during 2018â€“2019 in various disciplines for their features, costs, and impact on the community. We found that many mtngs could be improved significantly in terms of diversity, inclusivity, ECR promotion, ntwrking and career dvlpmnt, venue accessibility, and, importantly, reducing the mtngsâ€™ carbon footprint (Fig. 1 and Supplementary Information).\\nFig. 1: In-prsn academic cnfs are costly and exclusive.\\nfigure 1\\n\\nSummary analysis of features of 270 cnfs held in-prsn by over 150 scntfc societies and orgs during 2018â€“2019 in various scntfc disciplines (Supplementary Information). Aggregate analysis is presented from a database of in-prsn cnfs (https://elifeambassadors.github.io/improving-conferences/). Overall, the majority of mtngs wr held frequently (annually), and their formats and orgnztion lacked envrnmtl sustainability, incsive practices, and promotion and training opportunities for early-career rshrs.\\nFull size image\\nCarbon dioxide emissions\\n\\nThe increasing number and size of scntfc cnfs held in-prsn contribute to rising atmospheric carbon dioxide (CO2) levels and thus to climate change. There are over 8.4 million full-time and full-time-equivalent rshrs globally as of 2015, representing a growth of over 20% since 2007. With the current career norms, rshrs are expected to fly nationally and internationally, often several times a year, for scntfc mtngs. Cnf attendance accounts for 35% of a researcherâ€™s footprint2. In hosting hundreds to thousands of rshrs, cnfs produce substantial air-travel-related']}, 'status': 'finished_successfully', 'end_turn': None, 'weight': 1.0, 'metadata': {'timestamp_': 'absolute', 'message_type': None}, 'recipient': 'all'}, 'parent': '0e7a81e7-608d-4120-8776-21f724e13733', 'children': ['5b5ea666-6680-422b-b1da-635980ce49a8']}, '5b5ea666-6680-422b-b1da-635980ce49a8': {'id': '5b5ea666-6680-422b-b1da-635980ce49a8', 'message': {'id': '5b5ea666-6680-422b-b1da-635980ce49a8', 'author': {'role': 'assistant', 'name': None, 'metadata': {}}, 'create_time': 1681977402.694792, 'update_time': None, 'content': {'content_type': 'text', 'parts': [\"Conferences are pivotal parts of scientific enterprises, but large in-person meetings have several disadvantages. As pandemic experience has shown, online meetings are viable alternatives. Accelerating efforts to improve conferences in virtual formats can lead to a more equitable and sustainable conference culture.\\n\\nScientific conferences are important avenues for researchers to share and discuss research findings, to exchange ideas and insights, and to network for collaboration and career development. Organizing inclusive and useful scientific meetings is a significant responsibility shared by researchers, scientific societies, and other organizations worldwide. Prior to 2020, most conferences were held in-person and provided limited attendance opportunities for many researchers from diverse socioeconomic backgrounds, particularly early career researchers (ECRs), researchers from low- and middle-income countries, and junior principal investigators (PIs)1. Some conferences in select disciplines have implemented valuable changes for the community, becoming more receptive to attendees with families. Due to the COVID-19 pandemic, a major shift has occurred towards virtual conference formats, triggering discussions in the scientific community on the current and future formats and organization of conferences. Here we provide recommendations for improving scientific meetings towards more efficient, sustainable, and equitable gatherings.\\nThe many disadvantages of in-person conferences\\n\\nWe examined 270 national and international academic conferences held in person during 2018â€“2019 in various disciplines for their features, costs, and impact on the community. We found that many meetings could be improved significantly in terms of diversity, inclusivity, ECR promotion, networking and career development, venue accessibility, and, importantly, reducing the meetings' carbon footprint (Fig. 1 and Supplementary Information).\\nFig. 1: In-person academic conferences are costly and exclusive.\\nfigure 1\\n\\nSummary analysis of features of 270 conferences held in-person by over 150 scientific societies and organizations during 2018â€“2019 in various scientific disciplines (Supplementary Information). Aggregate analysis is presented from a database of in-person conferences (https://elifeambassadors.github.io/improving-conferences/). Overall, the majority of meetings were held frequently (annually), and their formats and organization lacked environmental sustainability, inclusive practices, and promotion and training opportunities for early-career researchers.\\nFull size image\\nCarbon dioxide emissions\\n\\nThe increasing number and size of scientific conferences held in-person contribute to rising atmospheric carbon dioxide (CO2) levels and thus to climate change. There are over 8.4 million full-time and full-time-equivalent researchers globally as of 2015, representing a growth of over 20% since 2007. With the current career norms, researchers are expected to fly nationally and internationally, often several times a year, for scientific meetings. Conference attendance accounts for 35% of a researcher's footprint2. In hosting hundreds to thousands of researchers, conferences produce substantial air-travel-related\"]}, 'status': 'finished_successfully', 'end_turn': True, 'weight': 1.0, 'metadata': {'message_type': None, 'model_slug': 'gpt-4', 'finish_details': {'type': 'stop', 'stop': '<|diff_marker|>'}, 'timestamp_': 'absolute'}, 'recipient': 'all'}, 'parent': '0ac6d621-f070-4451-826d-bb0a39ee3717', 'children': []}}\n",
      "Decode ðŸŒ€ & ðŸ›¸ Essence\n",
      "Parachute Career Exercises\n",
      "Condensing Text Complexity\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find small conversations\n",
    "small_conversations = []\n",
    "for conversation in data:\n",
    "    if len(conversation['mapping'].keys()) < 5:\n",
    "        small_conversations.append(conversation)\n",
    "\n",
    "# Print the number of small conversations and total conversations\n",
    "print('Number of small conversations: ', len(small_conversations))\n",
    "print('Total conversations: ', len(data))\n",
    "print('-' * 50)\n",
    "\n",
    "# Select 3 random conversations from the list of small conversations\n",
    "random_conversations = random.sample(small_conversations, k=3)\n",
    "\n",
    "for convo in small_conversations:\n",
    "    if convo['title'] == 'Virtual Conferences Solution.':\n",
    "        print(f\"{convo['title']}: {convo['mapping']}\")\n",
    "        print(\"Conversation:\")\n",
    "        print(json.dumps(convo, indent=4))\n",
    "        print('-' * 50)\n",
    "        \n",
    "# Print the titles of the selected conversations\n",
    "for conversation in random_conversations:\n",
    "    print(conversation['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree_structure(mapping, node_id, indent=\"\", fork_point=None):\n",
    "    node = mapping[node_id]\n",
    "    message = node.get('message', None)\n",
    "    role = message['author']['role'].capitalize() if message and message.get('author') else 'Root'\n",
    "    time = timestamp_to_str(message['create_time']) if message else 'None'\n",
    "    \n",
    "    # If current node has multiple children, update the fork point\n",
    "    if len(node['children']) > 1:\n",
    "        fork_point = node_id\n",
    "    \n",
    "    # Display the current node with the role, node_id, and timestamp\n",
    "    print(f\"{indent}â””â”€â”€ [[{role}: {node_id} ({time})]]\")\n",
    "    \n",
    "    # If there's a fork point, display it for reference\n",
    "    if fork_point:\n",
    "        branching_node = mapping[fork_point]\n",
    "        role_at_fork = branching_node['message']['author']['role'].capitalize() if branching_node['message'] and branching_node['message'].get('author') else 'Root'\n",
    "        print(f\"{indent}    [[Fork Point - {role_at_fork}: {fork_point}]]\")\n",
    "\n",
    "    for child_id in node['children']:\n",
    "        print_tree_structure(mapping, child_id, indent + \"    \", fork_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Conversation: New chat\n",
      "----------------------------------------\n",
      "Root Node: aaa19d94-3fe1-425b-86ae-972ef7ec44f9\n",
      "â””â”€â”€ [[System: 2e1d064f-c760-4bd7-a7f8-0280da43ee5b (None)]]\n",
      "    â””â”€â”€ [[User: aaa2a7c0-882e-4090-a6ea-3c6340fb3d5f (23-08-28 03:34)]]\n",
      "        â””â”€â”€ [[Assistant: 1a495d80-e0f5-4f83-8fde-3f3a2b0a131d (23-08-28 03:34)]]\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Conversation: Markdown Quotes Extraction\n",
      "----------------------------------------\n",
      "Root Node: aaa1c8af-888c-4640-85e5-2477b3993a92\n",
      "â””â”€â”€ [[System: 628b2957-a572-4e90-bf03-52bab0e3c04c (None)]]\n",
      "    â””â”€â”€ [[User: aaa2594c-131c-435d-be0a-1ad868c18068 (23-08-27 21:44)]]\n",
      "        â””â”€â”€ [[Assistant: 4bbfe999-4cd9-4393-b50a-d9b34d030a95 (23-08-27 21:44)]]\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Conversation: Autonomous Robotics Job Opportunity\n",
      "----------------------------------------\n",
      "Root Node: 9d8cda6d-624e-4fc9-9ab2-61929a0d1475\n",
      "â””â”€â”€ [[System: dba67e1c-9ac0-47e1-8922-8ded7c5bc4d0 (None)]]\n",
      "    â””â”€â”€ [[User: 54a7e6a1-fec7-4a45-81d8-1492fc70c6e6 (23-08-24 01:35)]]\n",
      "        â””â”€â”€ [[Assistant: c46f7048-8cfb-4e54-953e-cc3e3523a2f6 (23-08-24 01:35)]]\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_conversation_structure(convo):\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Conversation: {convo['title']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    root_node_id = next((node_id for node_id, node_data in convo['mapping'].items() if not node_data['parent']), None)\n",
    "    if not root_node_id:\n",
    "        return\n",
    "    \n",
    "    system_message_node_id = next((node_id for node_id, node_data in convo['mapping'].items() if node_data['message'] and node_data['message']['author']['role'] == 'system'), None)\n",
    "\n",
    "    print(f\"Root Node: {root_node_id}\")\n",
    "    if system_message_node_id:\n",
    "        system_time = timestamp_to_str(convo['mapping'][system_message_node_id]['message']['create_time'])\n",
    "        # print(f\"System Node: {system_message_node_id} ({system_time})\")\n",
    "\n",
    "        print_tree_structure(convo['mapping'], system_message_node_id)\n",
    "    print(\"=\" * 40)\n",
    "    print()\n",
    "\n",
    "# Process some of the small conversations\n",
    "for convo in small_conversations[:3]:\n",
    "    print_conversation_structure(convo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled: Import ChatGPT JSON Format                         | 5 (shallow depth)\n",
      "Sampled: Atoms on Earth Estimate                            | 19 (deep depth)\n",
      "Sampled: Customized Career Opportunity                      | 7 (intermediate depth)\n",
      "Sampled: RNN Concepts and Basics                            | 5 (slight branching)\n",
      "Sampled: Climate Change Presentation & Maps                 | 24 (profound depth)\n",
      "Sampled: Enhance Wear OS Reminders                          | 7 (moderate branching)\n",
      "Sampled: Full Workflow with Python                          | 25 (extensive branching)\n",
      "Sampled: Function Docs & Tests                              | 4 (few leaves)\n",
      "Sampled: Setting Up Python Project                          | 17 (considerable branching)\n",
      "Sampled: Summarizing Request & Response                     | 16 (many leaves)\n",
      "Sampled: Text Condensation: Techniques & Summary            | 10 (moderate leaves)\n",
      "Found conversation: GPT-3 Token Control. | b84bc33d-1495-49fd-805e-c42958209a06\n",
      "Sampled: CANA Censors CNN Headline                          | 45 (abundant leaves)\n",
      "Conversation Samples:\n",
      "Depth range: shallow           | 5  Import ChatGPT JSON Format (930bb6fd-00e1-4abc-8ab9-5f77c39bbb28)\n",
      "Depth range: intermediate      | 7  Customized Career Opportunity (f1e13b9e-5ef0-4413-a835-70a70d6a4e68)\n",
      "Depth range: deep              | 19 Atoms on Earth Estimate (e66c3fd1-93e7-403d-97ee-468bb0b0541b)\n",
      "Depth range: profound          | 24 Climate Change Presentation & Maps (98380a30-8005-4451-9d2a-bd0e8bbb2474)\n",
      "Branching range: slight        | 5  RNN Concepts and Basics (e40121e0-39ae-443b-8a63-d790dce5563d)\n",
      "Branching range: moderate      | 7  Enhance Wear OS Reminders (e173af46-0977-49fc-be2f-35f5e609c803)\n",
      "Branching range: considerable  | 17 Setting Up Python Project (1572c602-f153-4bd2-9fb3-f58dc85767cf)\n",
      "Branching range: extensive     | 25 Full Workflow with Python (76c10ac1-9c18-4fe5-9466-3f8189965bfc)\n",
      "Leaf range: few                | 4  Function Docs & Tests (6fa93e47-2339-49f9-acdb-77c13b52a5ab)\n",
      "Leaf range: moderate           | 10 Text Condensation: Techniques & Summary (47630559-2bbf-4d6f-b728-25c8a7d06811)\n",
      "Leaf range: many               | 16 Summarizing Request & Response (d52ae274-7d44-4902-8a3b-fee3101cb2bb)\n",
      "Leaf range: abundant           | 45 CANA Censors CNN Headline (523b252f-1eed-444c-8c98-99b8f53428c2)\n",
      "Root Node: a88eec46-80d6-4c3f-810d-f4c8868d84ad\n",
      "â””â”€â”€ [[System: 076adf85-94b6-42c2-8738-181964801053 (23-04-23 03:34)]]\n",
      "    [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "    â””â”€â”€ [[User: 72fe4134-3519-484e-b5cd-16887affc285 (23-04-23 03:34)]]\n",
      "        [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "        â””â”€â”€ [[Assistant: a17c71e2-1200-445a-b77f-9b5e4e111e5c (23-04-23 03:34)]]\n",
      "            [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "        â””â”€â”€ [[Assistant: 15916ca2-e6eb-4f79-b806-57ccf9039bb2 (23-04-23 03:36)]]\n",
      "            [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "    â””â”€â”€ [[User: cd07e965-e958-44ac-b8fc-3e4bc6b1882f (23-04-23 03:35)]]\n",
      "        [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "        â””â”€â”€ [[Assistant: df5626a2-a0c8-4121-bca5-bb7a5eb77a30 (23-04-23 03:35)]]\n",
      "            [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n"
     ]
    }
   ],
   "source": [
    "def traverse_tree(mapping, node_id, level):\n",
    "    children = mapping[node_id]['children']\n",
    "\n",
    "    if not children:\n",
    "        return 0, level, 1\n",
    "\n",
    "    branchings = len(children)\n",
    "    max_depth = level\n",
    "    total_leaves = 0\n",
    "\n",
    "    for child in children:\n",
    "        child_branchings, child_depth, child_leaves = traverse_tree(mapping, child, level + 1)\n",
    "        branchings += child_branchings\n",
    "        max_depth = max(max_depth, child_depth)\n",
    "        total_leaves += child_leaves\n",
    "\n",
    "    return branchings, max_depth, total_leaves\n",
    "\n",
    "test_convo_title = 'GPT-3 Token Control.'\n",
    "test_convo_id = 'b84bc33d-1495-49fd-805e-c42958209a06'\n",
    "\n",
    "def examine_test_conversation(data):\n",
    "    test_convo = None\n",
    "    conversation_sampling_record = []\n",
    "    conversation_sampling_criteria = {\n",
    "        'depth_ranges': {\n",
    "            'shallow': {\n",
    "                'range': (3, 5),\n",
    "                'sample': None\n",
    "            },\n",
    "            'intermediate': {\n",
    "                'range': (6, 10),\n",
    "                'sample': None\n",
    "            },\n",
    "            'deep': {\n",
    "                'range': (11, 20),\n",
    "                'sample': None\n",
    "            },\n",
    "            'profound': {\n",
    "                'range': (21, 100),\n",
    "                'sample': None\n",
    "            }\n",
    "        },\n",
    "        'branching_ranges': {\n",
    "            'slight': {\n",
    "                'range': (3, 5),\n",
    "                'sample': None\n",
    "            },\n",
    "            'moderate': {\n",
    "                'range': (6, 10),\n",
    "                'sample': None\n",
    "            },\n",
    "            'considerable': {\n",
    "                'range': (11, 20),\n",
    "                'sample': None\n",
    "            },\n",
    "            'extensive': {\n",
    "                'range': (21, 100),\n",
    "                'sample': None\n",
    "            }\n",
    "        },\n",
    "        'leaf_ranges': {\n",
    "            'few': {\n",
    "                'range': (3, 5),\n",
    "                'sample': None\n",
    "            },\n",
    "            'moderate': {\n",
    "                'range': (6, 10),\n",
    "                'sample': None\n",
    "            },\n",
    "            'many': {\n",
    "                'range': (11, 20),\n",
    "                'sample': None\n",
    "            },\n",
    "            'abundant': {\n",
    "                'range': (21, 100),\n",
    "                'sample': None\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    for convo in data:\n",
    "        root_node_id = next((node_id for node_id, node_data in convo['mapping'].items() if not node_data['parent']), None)\n",
    "\n",
    "        if not root_node_id:\n",
    "            print(f\"Conversation {convo['title']} ({convo['id']}) has no root node!\")\n",
    "            continue\n",
    "\n",
    "        # If the conversation is the test conversation, save it\n",
    "        if convo['title'] == test_convo_title and convo['id'] == test_convo_id:\n",
    "            test_convo = convo\n",
    "            print(f\"Found conversation: {convo['title']} | {convo['id']}\")\n",
    "\n",
    "        # Calculate the branchings, depth, and leaves of the conversation\n",
    "        branchings, depth, leaves = traverse_tree(convo['mapping'], root_node_id, 0)\n",
    "\n",
    "        # Check if the conversation meets any of the sampling criteria\n",
    "        # Note: The order of the criteria matters.\n",
    "        #       The first criteria that is met will be the one that is sampled.\n",
    "        #       This means that if a conversation meets multiple criteria,\n",
    "        #       it will only be sampled once (for the first criteria that it meets).\n",
    "        for depth_range_name, depth_range_data in conversation_sampling_criteria['depth_ranges'].items():\n",
    "            # If the conversation has already been sampled, skip the conversation\n",
    "            if convo['id'] in conversation_sampling_record:\n",
    "                #print(f\"Conversation {convo['title']} ({convo['id']}) has already been sampled!\")\n",
    "                break\n",
    "\n",
    "            # If we've already sampled a conversation for this depth range, skip the depth range\n",
    "            if depth_range_data['sample']:\n",
    "                #print(f\"Depth range {depth_range_name} has already been sampled!\")\n",
    "                continue\n",
    "\n",
    "            if depth_range_data['range'][0] <= depth <= depth_range_data['range'][1]:\n",
    "                # If the conversation meets the criteria, and the sample is empty, add it to the sample\n",
    "                if not depth_range_data['sample']:\n",
    "                    depth_range_sample = f\"{depth:<2} {convo['title']} ({convo['id']})\"\n",
    "                    depth_range_data['sample'] = depth_range_sample\n",
    "                    conversation_sampling_record.append(convo['id'])\n",
    "                    # Print the sample and the depth range\n",
    "                    print(f\"Sampled: {convo['title']:<50} | {depth} ({depth_range_name} depth)\")\n",
    "                    break\n",
    "        \n",
    "        for branching_range_name, branching_range_data in conversation_sampling_criteria['branching_ranges'].items():\n",
    "            # If the conversation has already been sampled, skip the conversation\n",
    "            if convo['id'] in conversation_sampling_record:\n",
    "                #print(f\"Conversation {convo['title']} ({convo['id']}) has already been sampled!\")\n",
    "                break\n",
    "\n",
    "            # If we've already sampled a conversation for this branching range, skip the branching range\n",
    "            if branching_range_data['sample']:\n",
    "                #print(f\"Branching range {branching_range_name} has already been sampled!\")\n",
    "                continue\n",
    "\n",
    "            if branching_range_data['range'][0] <= branchings <= branching_range_data['range'][1]:\n",
    "                # If the conversation meets the criteria, and the sample is empty, add it to the sample\n",
    "                if not branching_range_data['sample']:\n",
    "                    branching_range_sample = f\"{branchings:<2} {convo['title']} ({convo['id']})\"\n",
    "                    branching_range_data['sample'] = branching_range_sample\n",
    "                    conversation_sampling_record.append(convo['id'])\n",
    "                    # Print the sample and the branching range\n",
    "                    print(f\"Sampled: {convo['title']:<50} | {branchings} ({branching_range_name} branching)\")\n",
    "                    break\n",
    "\n",
    "        for leaf_range_name, leaf_range_data in conversation_sampling_criteria['leaf_ranges'].items():\n",
    "            # If the conversation has already been sampled, skip the conversation\n",
    "            if convo['id'] in conversation_sampling_record:\n",
    "                #print(f\"Conversation {convo['title']} ({convo['id']}) has already been sampled!\")\n",
    "                break\n",
    "\n",
    "            # If we've already sampled a conversation for this leaf range, skip the leaf range\n",
    "            if leaf_range_data['sample']:\n",
    "                #print(f\"Leaf range {leaf_range_name} has already been sampled!\")\n",
    "                continue\n",
    "\n",
    "            if leaf_range_data['range'][0] <= leaves <= leaf_range_data['range'][1]:\n",
    "                # If the conversation meets the criteria, and the sample is empty, add it to the sample\n",
    "                if not leaf_range_data['sample']:\n",
    "                    leaf_range_sample = f\"{leaves:<2} {convo['title']} ({convo['id']})\"\n",
    "                    leaf_range_data['sample'] = leaf_range_sample\n",
    "                    conversation_sampling_record.append(convo['id'])\n",
    "                    # Print the sample and the leaf range\n",
    "                    print(f\"Sampled: {convo['title']:<50} | {leaves} ({leaf_range_name} leaves)\")\n",
    "                    break\n",
    "                \n",
    "        #print(f\"{convo['title']:<50} Branchings, depth, leaves: {branchings}, {depth}, {leaves}\")\n",
    "\n",
    "    # Print the samples\n",
    "    print(\"Conversation Samples:\")\n",
    "    for depth_range_name, depth_range_data in conversation_sampling_criteria['depth_ranges'].items():\n",
    "        print(f\"Depth range: {depth_range_name:<17} | {depth_range_data['sample']}\")\n",
    "    for branching_range_name, branching_range_data in conversation_sampling_criteria['branching_ranges'].items():\n",
    "        print(f\"Branching range: {branching_range_name:<13} | {branching_range_data['sample']}\")\n",
    "    for leaf_range_name, leaf_range_data in conversation_sampling_criteria['leaf_ranges'].items():\n",
    "        print(f\"Leaf range: {leaf_range_name:<18} | {leaf_range_data['sample']}\")\n",
    "    \n",
    "    # Continue to printing the test conversation if it was found\n",
    "    if not test_convo:\n",
    "        print(\"Test conversation not found!\")\n",
    "        return\n",
    "\n",
    "    # We should only have one root node\n",
    "    root_node_ids = [node_id for node_id, node_data in test_convo['mapping'].items() if not node_data['parent']]    \n",
    "    if len(root_node_ids) > 1:\n",
    "        print(\"More than one root node!\")\n",
    "    \n",
    "    # Print the test conversation\n",
    "    for root_node_id in root_node_ids:\n",
    "        print(f\"Root Node: {root_node_id}\")\n",
    "        system_node_id = test_convo['mapping'][root_node_id]['children'][0]\n",
    "        print_tree_structure(test_convo['mapping'], system_node_id)\n",
    "\n",
    "\n",
    "examine_test_conversation(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found test conversation GPT-3 Token Control.: b84bc33d-1495-49fd-805e-c42958209a06\n",
      "========================================\n",
      "Conversation: GPT-3 Token Control. | b84bc33d-1495-49fd-805e-c42958209a06\n",
      "----------------------------------------\n",
      "â””â”€â”€ [[Root: a88eec46-80d6-4c3f-810d-f4c8868d84ad (None)]]\n",
      "    â””â”€â”€ [[System: 076adf85-94b6-42c2-8738-181964801053 (23-04-23 03:34)]]\n",
      "        [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "        â””â”€â”€ [[User: 72fe4134-3519-484e-b5cd-16887affc285 (23-04-23 03:34)]]\n",
      "            [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "            â””â”€â”€ [[Assistant: a17c71e2-1200-445a-b77f-9b5e4e111e5c (23-04-23 03:34)]]\n",
      "                [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "            â””â”€â”€ [[Assistant: 15916ca2-e6eb-4f79-b806-57ccf9039bb2 (23-04-23 03:36)]]\n",
      "                [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "        â””â”€â”€ [[User: cd07e965-e958-44ac-b8fc-3e4bc6b1882f (23-04-23 03:35)]]\n",
      "            [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "            â””â”€â”€ [[Assistant: df5626a2-a0c8-4121-bca5-bb7a5eb77a30 (23-04-23 03:35)]]\n",
      "                [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def print_test_convo_structure(test_convo):\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Conversation: {test_convo['title']} | {test_convo['id']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    root_node_ids = [node_id for node_id, node_data in test_convo['mapping'].items() if not node_data['parent']]\n",
    "    for root_node_id in root_node_ids:\n",
    "        print_tree_structure(test_convo['mapping'], root_node_id)\n",
    "    print(\"=\" * 40)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "def process_conversations(data):\n",
    "    test_convo = None\n",
    "\n",
    "    for convo in data:\n",
    "        root_node_id = next((node_id for node_id, node_data in convo['mapping'].items() if not node_data['parent']), None)\n",
    "\n",
    "        if not root_node_id:\n",
    "            continue\n",
    "\n",
    "        if convo['title'] == 'GPT-3 Token Control.':\n",
    "            test_convo = convo\n",
    "            print(f\"Found test conversation {convo['title']}: {convo['id']}\")\n",
    "\n",
    "    if not test_convo:\n",
    "        return\n",
    "\n",
    "    root_node_ids = [node_id for node_id, node_data in test_convo['mapping'].items() if not node_data['parent']]\n",
    "    \n",
    "    if len(root_node_ids) > 1:\n",
    "        print(\"More than one root node!\")\n",
    "\n",
    "    # Print the test conversation\n",
    "    print_test_convo_structure(test_convo)\n",
    "\n",
    "\n",
    "process_conversations(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
