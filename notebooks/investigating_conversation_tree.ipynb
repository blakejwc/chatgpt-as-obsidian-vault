{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Function to convert a timestamp to the required format\n",
    "def timestamp_to_str(timestamp):\n",
    "    if timestamp is None:\n",
    "        return 'None'\n",
    "    return datetime.utcfromtimestamp(timestamp).strftime('%y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of small conversations:  119\n",
      "Total conversations:  628\n",
      "--------------------------------------------------\n",
      "Organized Document on Mental Models\n",
      "\"Decoding Software Engineering Shorthand\"\n",
      "üìùResume from Career Transition thoughts\n"
     ]
    }
   ],
   "source": [
    "with open('../data/conversations.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Find small conversations\n",
    "small_conversations = []\n",
    "for conversation in data:\n",
    "    if len(conversation['mapping'].keys()) < 5:\n",
    "        small_conversations.append(conversation)\n",
    "\n",
    "# Print the number of small conversations and total conversations\n",
    "print('Number of small conversations: ', len(small_conversations))\n",
    "print('Total conversations: ', len(data))\n",
    "print('-' * 50)\n",
    "\n",
    "# Select 3 random conversations from the list of small conversations\n",
    "random_conversations = random.sample(small_conversations, k=3)\n",
    "\n",
    "# Print the titles of the selected conversations\n",
    "for conversation in random_conversations:\n",
    "    print(conversation['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree_structure(mapping, node_id, indent=\"\", fork_point=None):\n",
    "    node = mapping[node_id]\n",
    "    message = node.get('message', None)\n",
    "    role = message['author']['role'].capitalize() if message and message.get('author') else 'Root'\n",
    "    time = timestamp_to_str(message['create_time']) if message else 'None'\n",
    "    \n",
    "    # If current node has multiple children, update the fork point\n",
    "    if len(node['children']) > 1:\n",
    "        fork_point = node_id\n",
    "    \n",
    "    # Display the current node with the role, node_id, and timestamp\n",
    "    print(f\"{indent}‚îî‚îÄ‚îÄ [[{role}: {node_id} ({time})]]\")\n",
    "    \n",
    "    # If there's a fork point, display it for reference\n",
    "    if fork_point:\n",
    "        branching_node = mapping[fork_point]\n",
    "        role_at_fork = branching_node['message']['author']['role'].capitalize() if branching_node['message'] and branching_node['message'].get('author') else 'Root'\n",
    "        print(f\"{indent}    [[Fork Point - {role_at_fork}: {fork_point}]]\")\n",
    "\n",
    "    for child_id in node['children']:\n",
    "        print_tree_structure(mapping, child_id, indent + \"    \", fork_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Conversation: Python's Data Serpent\n",
      "----------------------------------------\n",
      "Root Node: aaa123b7-deec-411a-a943-961fcf81b338\n",
      "System Node: 6e53fb2e-3129-4643-9686-a8068e0a17a2 (23-07-12 02:00)\n",
      "‚îî‚îÄ‚îÄ [[System: 6e53fb2e-3129-4643-9686-a8068e0a17a2 (23-07-12 02:00)]]\n",
      "    ‚îî‚îÄ‚îÄ [[User: aaa2b441-f0ed-49a2-b7ab-cf2b2d144531 (23-07-12 02:00)]]\n",
      "        ‚îî‚îÄ‚îÄ [[Assistant: c00d2e38-e943-4439-a563-50b831ad3f98 (23-07-12 02:01)]]\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Conversation: Understanding God's Pronouns\n",
      "----------------------------------------\n",
      "Root Node: aaa1439c-5457-4b91-9311-370abaf806b1\n",
      "System Node: d7d3490a-94fc-4fe9-905c-5ebb50d7abc2 (23-07-11 02:10)\n",
      "‚îî‚îÄ‚îÄ [[System: d7d3490a-94fc-4fe9-905c-5ebb50d7abc2 (23-07-11 02:10)]]\n",
      "    ‚îî‚îÄ‚îÄ [[User: aaa2d053-903f-4243-a13d-ab2be61e176c (23-07-11 02:10)]]\n",
      "        ‚îî‚îÄ‚îÄ [[Assistant: b258cf15-5eaa-41fb-af0e-721074cc4aba (23-07-11 02:11)]]\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Conversation: Fine-tuning LLM with GPT\n",
      "----------------------------------------\n",
      "Root Node: aaa189f2-83fe-4fcc-90a1-5a49a79f3c47\n",
      "System Node: f03b55f5-e4bb-4e9e-8136-1589c42b942f (23-07-09 04:50)\n",
      "‚îî‚îÄ‚îÄ [[System: f03b55f5-e4bb-4e9e-8136-1589c42b942f (23-07-09 04:50)]]\n",
      "    ‚îî‚îÄ‚îÄ [[User: aaa26f46-8c3b-4ce9-ae80-c44bc4fa49a5 (23-07-09 04:50)]]\n",
      "        ‚îî‚îÄ‚îÄ [[Assistant: 285d052d-1c20-4ebc-a183-dd7394248c2b (23-07-09 04:50)]]\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_conversation_structure(convo):\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Conversation: {convo['title']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    root_node_id = next((node_id for node_id, node_data in convo['mapping'].items() if not node_data['parent']), None)\n",
    "    if not root_node_id:\n",
    "        return\n",
    "    \n",
    "    system_message_node_id = next((node_id for node_id, node_data in convo['mapping'].items() if node_data['message'] and node_data['message']['author']['role'] == 'system'), None)\n",
    "\n",
    "    print(f\"Root Node: {root_node_id}\")\n",
    "    if system_message_node_id:\n",
    "        system_time = timestamp_to_str(convo['mapping'][system_message_node_id]['message']['create_time'])\n",
    "        print(f\"System Node: {system_message_node_id} ({system_time})\")\n",
    "\n",
    "        print_tree_structure(convo['mapping'], system_message_node_id)\n",
    "    print(\"=\" * 40)\n",
    "    print()\n",
    "\n",
    "# Process some of the small conversations\n",
    "for convo in small_conversations[:3]:\n",
    "    print_conversation_structure(convo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled: Paper Art for Neural Networks                      | 5 (shallow depth)\n",
      "Sampled: Conversation Retrieval Error                       | 5 (slight branching)\n",
      "Sampled: Creating Non-GUI Visualizations                    | 7 (intermediate depth)\n",
      "Sampled: üîåPlugin API Breakdown                              | 7 (moderate branching)\n",
      "Sampled: Task Analysis & Trends                             | 47 (profound depth)\n",
      "Sampled: CSV Analysis & Trend Finding                       | 40 (extensive branching)\n",
      "Sampled: Humphrey Pump Fish Industry                        | 15 (deep depth)\n",
      "Sampled: Fish Transfer Methods: Summary                     | 13 (considerable branching)\n",
      "Sampled: Image processing turning into puzzle               | 5 (few leaves)\n",
      "Sampled: Company List Comparison                            | 11 (many leaves)\n",
      "Sampled: AIMaster Plugin Capabilities                       | 6 (moderate leaves)\n",
      "Found conversation: GPT-3 Token Control. | b84bc33d-1495-49fd-805e-c42958209a06\n",
      "Sampled: CANA Censors CNN Headline                          | 45 (abundant leaves)\n",
      "Conversation Samples:\n",
      "Depth range: shallow           | 5  Paper Art for Neural Networks (2f7d2441-75e3-4d34-80ba-9d7210491ecc)\n",
      "Depth range: intermediate      | 7  Creating Non-GUI Visualizations (eb2b1183-bf16-42fb-9a84-5844d355265f)\n",
      "Depth range: deep              | 15 Humphrey Pump Fish Industry (0a0a6315-f77a-4655-97fb-89f6632d672e)\n",
      "Depth range: profound          | 47 Task Analysis & Trends (a212a440-cb19-4cc2-b800-985024df9ac2)\n",
      "Branching range: slight        | 5  Conversation Retrieval Error (cb12a024-ca01-4b9d-8c6a-082254462809)\n",
      "Branching range: moderate      | 7  üîåPlugin API Breakdown (0f327b20-f7e0-41ca-9faf-7bcbd1278def)\n",
      "Branching range: considerable  | 13 Fish Transfer Methods: Summary (8487b782-d0df-49e0-8a25-3a97b7ea0654)\n",
      "Branching range: extensive     | 40 CSV Analysis & Trend Finding (78a5be0f-90c8-4deb-a043-d609c3370c42)\n",
      "Leaf range: few                | 5  Image processing turning into puzzle (69c684d1-da82-466a-bf0c-890b6ee23196)\n",
      "Leaf range: moderate           | 6  AIMaster Plugin Capabilities (37e804b7-1143-4088-ad38-3bb85788e163)\n",
      "Leaf range: many               | 11 Company List Comparison (9d776d41-ee1e-4adf-b343-5b76caaa45fa)\n",
      "Leaf range: abundant           | 45 CANA Censors CNN Headline (523b252f-1eed-444c-8c98-99b8f53428c2)\n",
      "Root Node: a88eec46-80d6-4c3f-810d-f4c8868d84ad\n",
      "‚îî‚îÄ‚îÄ [[System: 076adf85-94b6-42c2-8738-181964801053 (23-04-23 03:34)]]\n",
      "    [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "    ‚îî‚îÄ‚îÄ [[User: 72fe4134-3519-484e-b5cd-16887affc285 (23-04-23 03:34)]]\n",
      "        [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "        ‚îî‚îÄ‚îÄ [[Assistant: a17c71e2-1200-445a-b77f-9b5e4e111e5c (23-04-23 03:34)]]\n",
      "            [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "        ‚îî‚îÄ‚îÄ [[Assistant: 15916ca2-e6eb-4f79-b806-57ccf9039bb2 (23-04-23 03:36)]]\n",
      "            [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "    ‚îî‚îÄ‚îÄ [[User: cd07e965-e958-44ac-b8fc-3e4bc6b1882f (23-04-23 03:35)]]\n",
      "        [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "        ‚îî‚îÄ‚îÄ [[Assistant: df5626a2-a0c8-4121-bca5-bb7a5eb77a30 (23-04-23 03:35)]]\n",
      "            [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n"
     ]
    }
   ],
   "source": [
    "def traverse_tree(mapping, node_id, level):\n",
    "    children = mapping[node_id]['children']\n",
    "\n",
    "    if not children:\n",
    "        return 0, level, 1\n",
    "\n",
    "    branchings = len(children)\n",
    "    max_depth = level\n",
    "    total_leaves = 0\n",
    "\n",
    "    for child in children:\n",
    "        child_branchings, child_depth, child_leaves = traverse_tree(mapping, child, level + 1)\n",
    "        branchings += child_branchings\n",
    "        max_depth = max(max_depth, child_depth)\n",
    "        total_leaves += child_leaves\n",
    "\n",
    "    return branchings, max_depth, total_leaves\n",
    "\n",
    "test_convo_title = 'GPT-3 Token Control.'\n",
    "test_convo_id = 'b84bc33d-1495-49fd-805e-c42958209a06'\n",
    "\n",
    "def examine_test_conversation(data):\n",
    "    test_convo = None\n",
    "    conversation_sampling_record = []\n",
    "    conversation_sampling_criteria = {\n",
    "        'depth_ranges': {\n",
    "            'shallow': {\n",
    "                'range': (3, 5),\n",
    "                'sample': None\n",
    "            },\n",
    "            'intermediate': {\n",
    "                'range': (6, 10),\n",
    "                'sample': None\n",
    "            },\n",
    "            'deep': {\n",
    "                'range': (11, 20),\n",
    "                'sample': None\n",
    "            },\n",
    "            'profound': {\n",
    "                'range': (21, 100),\n",
    "                'sample': None\n",
    "            }\n",
    "        },\n",
    "        'branching_ranges': {\n",
    "            'slight': {\n",
    "                'range': (3, 5),\n",
    "                'sample': None\n",
    "            },\n",
    "            'moderate': {\n",
    "                'range': (6, 10),\n",
    "                'sample': None\n",
    "            },\n",
    "            'considerable': {\n",
    "                'range': (11, 20),\n",
    "                'sample': None\n",
    "            },\n",
    "            'extensive': {\n",
    "                'range': (21, 100),\n",
    "                'sample': None\n",
    "            }\n",
    "        },\n",
    "        'leaf_ranges': {\n",
    "            'few': {\n",
    "                'range': (3, 5),\n",
    "                'sample': None\n",
    "            },\n",
    "            'moderate': {\n",
    "                'range': (6, 10),\n",
    "                'sample': None\n",
    "            },\n",
    "            'many': {\n",
    "                'range': (11, 20),\n",
    "                'sample': None\n",
    "            },\n",
    "            'abundant': {\n",
    "                'range': (21, 100),\n",
    "                'sample': None\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    for convo in data:\n",
    "        root_node_id = next((node_id for node_id, node_data in convo['mapping'].items() if not node_data['parent']), None)\n",
    "\n",
    "        if not root_node_id:\n",
    "            print(f\"Conversation {convo['title']} ({convo['id']}) has no root node!\")\n",
    "            continue\n",
    "\n",
    "        # If the conversation is the test conversation, save it\n",
    "        if convo['title'] == test_convo_title and convo['id'] == test_convo_id:\n",
    "            test_convo = convo\n",
    "            print(f\"Found conversation: {convo['title']} | {convo['id']}\")\n",
    "\n",
    "        # Calculate the branchings, depth, and leaves of the conversation\n",
    "        branchings, depth, leaves = traverse_tree(convo['mapping'], root_node_id, 0)\n",
    "\n",
    "        # Check if the conversation meets any of the sampling criteria\n",
    "        # Note: The order of the criteria matters.\n",
    "        #       The first criteria that is met will be the one that is sampled.\n",
    "        #       This means that if a conversation meets multiple criteria,\n",
    "        #       it will only be sampled once (for the first criteria that it meets).\n",
    "        for depth_range_name, depth_range_data in conversation_sampling_criteria['depth_ranges'].items():\n",
    "            # If the conversation has already been sampled, skip the conversation\n",
    "            if convo['id'] in conversation_sampling_record:\n",
    "                #print(f\"Conversation {convo['title']} ({convo['id']}) has already been sampled!\")\n",
    "                break\n",
    "\n",
    "            # If we've already sampled a conversation for this depth range, skip the depth range\n",
    "            if depth_range_data['sample']:\n",
    "                #print(f\"Depth range {depth_range_name} has already been sampled!\")\n",
    "                continue\n",
    "\n",
    "            if depth_range_data['range'][0] <= depth <= depth_range_data['range'][1]:\n",
    "                # If the conversation meets the criteria, and the sample is empty, add it to the sample\n",
    "                if not depth_range_data['sample']:\n",
    "                    depth_range_sample = f\"{depth:<2} {convo['title']} ({convo['id']})\"\n",
    "                    depth_range_data['sample'] = depth_range_sample\n",
    "                    conversation_sampling_record.append(convo['id'])\n",
    "                    # Print the sample and the depth range\n",
    "                    print(f\"Sampled: {convo['title']:<50} | {depth} ({depth_range_name} depth)\")\n",
    "                    break\n",
    "        \n",
    "        for branching_range_name, branching_range_data in conversation_sampling_criteria['branching_ranges'].items():\n",
    "            # If the conversation has already been sampled, skip the conversation\n",
    "            if convo['id'] in conversation_sampling_record:\n",
    "                #print(f\"Conversation {convo['title']} ({convo['id']}) has already been sampled!\")\n",
    "                break\n",
    "\n",
    "            # If we've already sampled a conversation for this branching range, skip the branching range\n",
    "            if branching_range_data['sample']:\n",
    "                #print(f\"Branching range {branching_range_name} has already been sampled!\")\n",
    "                continue\n",
    "\n",
    "            if branching_range_data['range'][0] <= branchings <= branching_range_data['range'][1]:\n",
    "                # If the conversation meets the criteria, and the sample is empty, add it to the sample\n",
    "                if not branching_range_data['sample']:\n",
    "                    branching_range_sample = f\"{branchings:<2} {convo['title']} ({convo['id']})\"\n",
    "                    branching_range_data['sample'] = branching_range_sample\n",
    "                    conversation_sampling_record.append(convo['id'])\n",
    "                    # Print the sample and the branching range\n",
    "                    print(f\"Sampled: {convo['title']:<50} | {branchings} ({branching_range_name} branching)\")\n",
    "                    break\n",
    "\n",
    "        for leaf_range_name, leaf_range_data in conversation_sampling_criteria['leaf_ranges'].items():\n",
    "            # If the conversation has already been sampled, skip the conversation\n",
    "            if convo['id'] in conversation_sampling_record:\n",
    "                #print(f\"Conversation {convo['title']} ({convo['id']}) has already been sampled!\")\n",
    "                break\n",
    "\n",
    "            # If we've already sampled a conversation for this leaf range, skip the leaf range\n",
    "            if leaf_range_data['sample']:\n",
    "                #print(f\"Leaf range {leaf_range_name} has already been sampled!\")\n",
    "                continue\n",
    "\n",
    "            if leaf_range_data['range'][0] <= leaves <= leaf_range_data['range'][1]:\n",
    "                # If the conversation meets the criteria, and the sample is empty, add it to the sample\n",
    "                if not leaf_range_data['sample']:\n",
    "                    leaf_range_sample = f\"{leaves:<2} {convo['title']} ({convo['id']})\"\n",
    "                    leaf_range_data['sample'] = leaf_range_sample\n",
    "                    conversation_sampling_record.append(convo['id'])\n",
    "                    # Print the sample and the leaf range\n",
    "                    print(f\"Sampled: {convo['title']:<50} | {leaves} ({leaf_range_name} leaves)\")\n",
    "                    break\n",
    "                \n",
    "        #print(f\"{convo['title']:<50} Branchings, depth, leaves: {branchings}, {depth}, {leaves}\")\n",
    "\n",
    "    # Print the samples\n",
    "    print(\"Conversation Samples:\")\n",
    "    for depth_range_name, depth_range_data in conversation_sampling_criteria['depth_ranges'].items():\n",
    "        print(f\"Depth range: {depth_range_name:<17} | {depth_range_data['sample']}\")\n",
    "    for branching_range_name, branching_range_data in conversation_sampling_criteria['branching_ranges'].items():\n",
    "        print(f\"Branching range: {branching_range_name:<13} | {branching_range_data['sample']}\")\n",
    "    for leaf_range_name, leaf_range_data in conversation_sampling_criteria['leaf_ranges'].items():\n",
    "        print(f\"Leaf range: {leaf_range_name:<18} | {leaf_range_data['sample']}\")\n",
    "    \n",
    "    # Continue to printing the test conversation if it was found\n",
    "    if not test_convo:\n",
    "        print(\"Test conversation not found!\")\n",
    "        return\n",
    "\n",
    "    # We should only have one root node\n",
    "    root_node_ids = [node_id for node_id, node_data in test_convo['mapping'].items() if not node_data['parent']]    \n",
    "    if len(root_node_ids) > 1:\n",
    "        print(\"More than one root node!\")\n",
    "    \n",
    "    # Print the test conversation\n",
    "    for root_node_id in root_node_ids:\n",
    "        print(f\"Root Node: {root_node_id}\")\n",
    "        system_node_id = test_convo['mapping'][root_node_id]['children'][0]\n",
    "        print_tree_structure(test_convo['mapping'], system_node_id)\n",
    "\n",
    "\n",
    "examine_test_conversation(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found test conversation GPT-3 Token Control.: b84bc33d-1495-49fd-805e-c42958209a06\n",
      "========================================\n",
      "Conversation: GPT-3 Token Control. | b84bc33d-1495-49fd-805e-c42958209a06\n",
      "----------------------------------------\n",
      "‚îî‚îÄ‚îÄ [[Root: a88eec46-80d6-4c3f-810d-f4c8868d84ad (None)]]\n",
      "    ‚îî‚îÄ‚îÄ [[System: 076adf85-94b6-42c2-8738-181964801053 (23-04-23 03:34)]]\n",
      "        [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "        ‚îî‚îÄ‚îÄ [[User: 72fe4134-3519-484e-b5cd-16887affc285 (23-04-23 03:34)]]\n",
      "            [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "            ‚îî‚îÄ‚îÄ [[Assistant: a17c71e2-1200-445a-b77f-9b5e4e111e5c (23-04-23 03:34)]]\n",
      "                [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "            ‚îî‚îÄ‚îÄ [[Assistant: 15916ca2-e6eb-4f79-b806-57ccf9039bb2 (23-04-23 03:36)]]\n",
      "                [[Fork Point - User: 72fe4134-3519-484e-b5cd-16887affc285]]\n",
      "        ‚îî‚îÄ‚îÄ [[User: cd07e965-e958-44ac-b8fc-3e4bc6b1882f (23-04-23 03:35)]]\n",
      "            [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "            ‚îî‚îÄ‚îÄ [[Assistant: df5626a2-a0c8-4121-bca5-bb7a5eb77a30 (23-04-23 03:35)]]\n",
      "                [[Fork Point - System: 076adf85-94b6-42c2-8738-181964801053]]\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def print_test_convo_structure(test_convo):\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Conversation: {test_convo['title']} | {test_convo['id']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    root_node_ids = [node_id for node_id, node_data in test_convo['mapping'].items() if not node_data['parent']]\n",
    "    for root_node_id in root_node_ids:\n",
    "        print_tree_structure(test_convo['mapping'], root_node_id)\n",
    "    print(\"=\" * 40)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "def process_conversations(data):\n",
    "    test_convo = None\n",
    "\n",
    "    for convo in data:\n",
    "        root_node_id = next((node_id for node_id, node_data in convo['mapping'].items() if not node_data['parent']), None)\n",
    "\n",
    "        if not root_node_id:\n",
    "            continue\n",
    "\n",
    "        if convo['title'] == 'GPT-3 Token Control.':\n",
    "            test_convo = convo\n",
    "            print(f\"Found test conversation {convo['title']}: {convo['id']}\")\n",
    "\n",
    "    if not test_convo:\n",
    "        return\n",
    "\n",
    "    root_node_ids = [node_id for node_id, node_data in test_convo['mapping'].items() if not node_data['parent']]\n",
    "    \n",
    "    if len(root_node_ids) > 1:\n",
    "        print(\"More than one root node!\")\n",
    "\n",
    "    # Print the test conversation\n",
    "    print_test_convo_structure(test_convo)\n",
    "\n",
    "\n",
    "process_conversations(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
